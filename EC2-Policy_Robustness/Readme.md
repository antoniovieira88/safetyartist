# Case Study 2 - Safety Analysis of Agents with Safe Reinforcement Learning

Reference: LIU Z. et al., Constrained Variational Policy Optimization for Safe Reinforcement Learning. In: Proceedings of the 39th International Conference on Machine Learning (ICML 2022), p. 13644-13668. Baltimore, MD, USA, PMLR - Proceedings of Machine Learning Research, 2022.

Original Source Code: BEHZADAN, V.; MUNIR, A. GitHub - behzadanksu/rl-attack: Adversarial Example Attacks on Policy Learners. Available at: <https://github.com/liuzuxin/cvpo-safe-rl>, 2023. Access in Sept. 20, 2023.

